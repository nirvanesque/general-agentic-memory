# GAM Benchmarks å¿«é€Ÿå¼€å§‹æŒ‡å—

è¿™æ˜¯ä¸€ä¸ª5åˆ†é’Ÿå¿«é€Ÿä¸Šæ‰‹æŒ‡å—ï¼Œå¸®åŠ©ä½ å¿«é€Ÿè¿è¡Œç¬¬ä¸€ä¸ªè¯„ä¼°ã€‚

## âš¡ è¶…å¿«é€Ÿå¼€å§‹

```bash
# 1. å®‰è£…
pip install -r requirements.txt

# 2. è®¾ç½®ç¯å¢ƒå˜é‡
export OPENAI_API_KEY="your_api_key_here"

# 3. è¿è¡Œï¼ˆå‡è®¾ä½ å·²æœ‰æ•°æ®ï¼‰
bash scripts/eval_hotpotqa.sh --data-path data/hotpotqa.json --max-samples 10
```

å®Œæˆï¼ğŸ‰

## ğŸ“ è¯¦ç»†æ­¥éª¤

### æ­¥éª¤ 1: å®‰è£…ä¾èµ–

```bash
cd general-agentic-memory
pip install -r requirements.txt
pip install -e .
```

### æ­¥éª¤ 2: å‡†å¤‡æ•°æ®

åˆ›å»ºæ•°æ®ç›®å½•ï¼š
```bash
mkdir -p data
```

ä¸‹è½½æˆ–å‡†å¤‡ä½ çš„æ•°æ®é›†ï¼š
- HotpotQA: `data/hotpotqa.json`
- LoCoMo: `data/locomo.json`
- RULER: `data/ruler.jsonl`
- NarrativeQA: ä¼šè‡ªåŠ¨ä» HuggingFace ä¸‹è½½

### æ­¥éª¤ 3: è®¾ç½®ç¯å¢ƒ

```bash
# å¿…éœ€ï¼ˆå¦‚æœä½¿ç”¨ OpenAIï¼‰
export OPENAI_API_KEY="sk-..."

# å¯é€‰ï¼šè‡ªå®šä¹‰APIç«¯ç‚¹
export OPENAI_API_BASE="https://your-endpoint.com/v1"
```

### æ­¥éª¤ 4: è¿è¡Œè¯„ä¼°

#### æ–¹å¼ä¸€ï¼šä½¿ç”¨ Shell è„šæœ¬ï¼ˆæ¨èæ–°æ‰‹ï¼‰

```bash
# HotpotQA - å¿«é€Ÿæµ‹è¯•ï¼ˆ10ä¸ªæ ·æœ¬ï¼‰
bash scripts/eval_hotpotqa.sh --data-path data/hotpotqa.json --max-samples 10

# å®Œæ•´è¯„ä¼°
bash scripts/eval_hotpotqa.sh --data-path data/hotpotqa.json
```

#### æ–¹å¼äºŒï¼šä½¿ç”¨ Python CLIï¼ˆæ›´çµæ´»ï¼‰

```bash
python -m eval.run \
    --dataset hotpotqa \
    --data-path data/hotpotqa.json \
    --generator openai \
    --model gpt-4 \
    --retriever dense \
    --max-samples 10
```

### æ­¥éª¤ 5: æŸ¥çœ‹ç»“æœ

ç»“æœä¿å­˜åœ¨ `outputs/` ç›®å½•ï¼š

```bash
ls -lh outputs/hotpotqa/
cat outputs/hotpotqa/HotpotQABenchmark_*.json
```

## ğŸ¯ å¸¸è§åœºæ™¯

### åœºæ™¯ 1: å¿«é€Ÿæµ‹è¯•ï¼ˆ10ä¸ªæ ·æœ¬ï¼‰

```bash
bash scripts/eval_hotpotqa.sh \
    --data-path data/hotpotqa.json \
    --max-samples 10
```

### åœºæ™¯ 2: ä½¿ç”¨ä¸åŒçš„æ¨¡å‹

```bash
python -m eval.run \
    --dataset hotpotqa \
    --data-path data/hotpotqa.json \
    --model gpt-3.5-turbo \
    --max-samples 50
```

### åœºæ™¯ 3: ä½¿ç”¨æœ¬åœ°æ¨¡å‹ï¼ˆVLLMï¼‰

```bash
python -m eval.run \
    --dataset hotpotqa \
    --data-path data/hotpotqa.json \
    --generator vllm \
    --model meta-llama/Llama-3-8B
```

### åœºæ™¯ 4: ä½¿ç”¨ BM25 æ£€ç´¢å™¨

```bash
python -m eval.run \
    --dataset hotpotqa \
    --data-path data/hotpotqa.json \
    --retriever bm25
```

### åœºæ™¯ 5: è¯„ä¼°æ‰€æœ‰æ•°æ®é›†

```bash
bash scripts/eval_all.sh
```

## ğŸ”§ æ•…éšœæ’é™¤

### é—®é¢˜ 1: API Key é”™è¯¯

```bash
# æ£€æŸ¥ç¯å¢ƒå˜é‡
echo $OPENAI_API_KEY

# å¦‚æœä¸ºç©ºï¼Œè®¾ç½®å®ƒ
export OPENAI_API_KEY="your_key"
```

### é—®é¢˜ 2: æ•°æ®æ–‡ä»¶æœªæ‰¾åˆ°

```bash
# æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
ls -lh data/

# ç¡®ä¿è·¯å¾„æ­£ç¡®
bash scripts/eval_hotpotqa.sh --data-path /absolute/path/to/hotpotqa.json
```

### é—®é¢˜ 3: å†…å­˜ä¸è¶³

```bash
# å‡å° chunk size æˆ– æ ·æœ¬æ•°
python -m eval.run \
    --dataset hotpotqa \
    --data-path data/hotpotqa.json \
    --chunk-size 1000 \
    --max-samples 10
```

### é—®é¢˜ 4: NLTK æ•°æ®æœªä¸‹è½½

```python
# æ‰‹åŠ¨ä¸‹è½½
python -c "import nltk; nltk.download('punkt_tab')"
```

## ğŸ“š ä¸‹ä¸€æ­¥

- é˜…è¯»å®Œæ•´æ–‡æ¡£: [README.md](README.md)
- äº†è§£å¦‚ä½•æ·»åŠ æ–°æ•°æ®é›†: [MIGRATION.md](MIGRATION.md)
- æŸ¥çœ‹æ›´æ–°æ—¥å¿—: [CHANGELOG.md](CHANGELOG.md)

## ğŸ’¡ æç¤º

1. **é¦–æ¬¡è¿è¡Œ**: ä½¿ç”¨ `--max-samples 10` å¿«é€ŸéªŒè¯
2. **èŠ‚çœæˆæœ¬**: ä½¿ç”¨ `gpt-3.5-turbo` è€Œä¸æ˜¯ `gpt-4`
3. **é™é»˜æ¨¡å¼**: æ·»åŠ  `--quiet` å‡å°‘è¾“å‡º
4. **ä¿å­˜ç»“æœ**: é»˜è®¤ä¿å­˜åœ¨ `outputs/`ï¼Œå¯ç”¨ `--output-dir` ä¿®æ”¹
5. **Shell è„šæœ¬**: æŸ¥çœ‹è„šæœ¬å†…å®¹äº†è§£é»˜è®¤å‚æ•°

## ğŸ‰ å®Œæˆï¼

ç°åœ¨ä½ å·²ç»å¯ä»¥è¿è¡Œ GAM è¯„ä¼°äº†ï¼å¦‚æœ‰é—®é¢˜ï¼Œè¯·æŸ¥çœ‹å®Œæ•´æ–‡æ¡£æˆ–æäº¤ Issueã€‚

Happy Benchmarking! ğŸš€

